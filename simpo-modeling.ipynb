{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11499375,"sourceType":"datasetVersion","datasetId":7209026}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"%%bash\nrm -rf /kaggle/working/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:40:52.385083Z","iopub.execute_input":"2025-04-22T04:40:52.385411Z","iopub.status.idle":"2025-04-22T04:40:52.408037Z","shell.execute_reply.started":"2025-04-22T04:40:52.385381Z","shell.execute_reply":"2025-04-22T04:40:52.407296Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%%bash\npip install --upgrade transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:24:07.768173Z","iopub.execute_input":"2025-04-22T03:24:07.768473Z","iopub.status.idle":"2025-04-22T03:24:19.681350Z","shell.execute_reply.started":"2025-04-22T03:24:07.768451Z","shell.execute_reply":"2025-04-22T03:24:19.680821Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.4/10.4 MB 82.4 MB/s eta 0:00:00\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\nSuccessfully installed transformers-4.51.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install torch==2.2.2+cu118 torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n!pip install flash-attn --no-build-isolation\n!pip install accelerate transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T19:46:25.646709Z","iopub.execute_input":"2025-04-21T19:46:25.646952Z","iopub.status.idle":"2025-04-21T19:49:00.127092Z","shell.execute_reply.started":"2025-04-21T19:46:25.646935Z","shell.execute_reply":"2025-04-21T19:49:00.126053Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\nDownloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.0.1\nLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\nCollecting torch==2.2.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (819.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.2/819.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2+cu118) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2+cu118) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2+cu118) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2+cu118) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2+cu118) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2+cu118) (2024.12.0)\nCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.2.2+cu118)\n  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.2.2+cu118)\n  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.2.2+cu118)\n  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu11==8.7.0.84 (from torch==2.2.2+cu118)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.2.2+cu118)\n  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.2.2+cu118)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.2.2+cu118)\n  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.2.2+cu118)\n  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.2.2+cu118)\n  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-nccl-cu11==2.19.3 (from torch==2.2.2+cu118)\n  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.2.2+cu118)\n  Downloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.2+cu118)\n  Downloading https://download.pytorch.org/whl/triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchvision-0.20.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchvision-0.18.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchvision-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchaudio-2.5.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hINFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n  Downloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchaudio-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchaudio-2.3.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading torchaudio-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2+cu118) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2+cu118) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)\nInstalling collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchaudio, torchvision\n  Attempting uninstall: triton\n    Found existing installation: triton 3.1.0\n    Uninstalling triton-3.1.0:\n      Successfully uninstalled triton-3.1.0\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu124\n    Uninstalling torch-2.5.1+cu124:\n      Successfully uninstalled torch-2.5.1+cu124\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.5.1+cu124\n    Uninstalling torchaudio-2.5.1+cu124:\n      Successfully uninstalled torchaudio-2.5.1+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu124\n    Uninstalling torchvision-0.20.1+cu124:\n      Successfully uninstalled torchvision-0.20.1+cu124\nSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3 nvidia-nvtx-cu11-11.8.86 torch-2.2.2+cu118 torchaudio-2.2.2+cu118 torchvision-0.17.2+cu118 triton-2.2.0\nCollecting flash-attn\n  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.2.2+cu118)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.13.1)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.8.86)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->flash-attn) (1.3.0)\nBuilding wheels for collected packages: flash-attn\n  Building wheel for flash-attn (setup.py) ... \u001b[?25l  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\nerror\n\u001b[31m  ERROR: Failed building wheel for flash-attn\u001b[0m\u001b[31m\n\u001b[0m\u001b[?25h  Running setup.py clean for flash-attn\nFailed to build flash-attn\n\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (flash-attn)\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.0.dev0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.2.2+cu118)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0.0,>=1.17->accelerate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.86)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0.0,>=1.17->accelerate) (2024.2.0)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!git clone https://github.com/princeton-nlp/SimPO.git\n%cd SimPO\n!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:15.721313Z","iopub.execute_input":"2025-04-22T04:41:15.722056Z","iopub.status.idle":"2025-04-22T04:41:18.358347Z","shell.execute_reply.started":"2025-04-22T04:41:15.722028Z","shell.execute_reply":"2025-04-22T04:41:18.357682Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'SimPO'...\nremote: Enumerating objects: 330, done.\u001b[K\nremote: Counting objects: 100% (161/161), done.\u001b[K\nremote: Compressing objects: 100% (58/58), done.\u001b[K\nremote: Total 330 (delta 125), reused 103 (delta 103), pack-reused 169 (from 1)\u001b[K\nReceiving objects: 100% (330/330), 2.99 MiB | 23.94 MiB/s, done.\nResolving deltas: 100% (176/176), done.\n/kaggle/working/SimPO\n\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install ace_tools_open","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:25.216760Z","iopub.execute_input":"2025-04-22T04:41:25.217463Z","iopub.status.idle":"2025-04-22T04:41:28.743665Z","shell.execute_reply.started":"2025-04-22T04:41:25.217429Z","shell.execute_reply":"2025-04-22T04:41:28.742952Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting ace_tools_open\n  Downloading ace_tools_open-0.1.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ace_tools_open) (2.2.3)\nCollecting itables (from ace_tools_open)\n  Downloading itables-2.3.0-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from ace_tools_open) (7.34.0)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (75.1.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.7.5)\nRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (5.7.1)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->ace_tools_open) (4.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from itables->ace_tools_open) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ace_tools_open) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ace_tools_open) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ace_tools_open) (2025.2)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->ace_tools_open) (0.8.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->itables->ace_tools_open) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->itables->ace_tools_open) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->itables->ace_tools_open) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->itables->ace_tools_open) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->itables->ace_tools_open) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->itables->ace_tools_open) (2.4.1)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->ace_tools_open) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->ace_tools_open) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ace_tools_open) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->itables->ace_tools_open) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->itables->ace_tools_open) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->itables->ace_tools_open) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->itables->ace_tools_open) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->itables->ace_tools_open) (2024.2.0)\nDownloading ace_tools_open-0.1.0-py3-none-any.whl (3.0 kB)\nDownloading itables-2.3.0-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: itables, ace_tools_open\nSuccessfully installed ace_tools_open-0.1.0 itables-2.3.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset\nimport os\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport ace_tools_open as tools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:39.713525Z","iopub.execute_input":"2025-04-22T04:41:39.713840Z","iopub.status.idle":"2025-04-22T04:41:42.038139Z","shell.execute_reply.started":"2025-04-22T04:41:39.713815Z","shell.execute_reply":"2025-04-22T04:41:42.037578Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"pos_paths = [\n    \"/kaggle/input/simpo-dataset/Civil Code (part one).xlsx\",\n    \"/kaggle/input/simpo-dataset/Civil Code (part two).xlsx\"\n]\nneg_path = \"/kaggle/input/simpo-dataset/Negative class (2).xlsx\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:42.039221Z","iopub.execute_input":"2025-04-22T04:41:42.039653Z","iopub.status.idle":"2025-04-22T04:41:42.043415Z","shell.execute_reply.started":"2025-04-22T04:41:42.039632Z","shell.execute_reply":"2025-04-22T04:41:42.042608Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df_pos1 = pd.read_excel(pos_paths[0])\ndf_pos2 = pd.read_excel(pos_paths[1])\ndf_neg = pd.read_excel(neg_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:42.044689Z","iopub.execute_input":"2025-04-22T04:41:42.045124Z","iopub.status.idle":"2025-04-22T04:41:42.737490Z","shell.execute_reply.started":"2025-04-22T04:41:42.045096Z","shell.execute_reply":"2025-04-22T04:41:42.736959Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_pos = pd.concat([df_pos1, df_pos2], ignore_index=True)\ndf_pos['label'] = 1\ndf_neg['label'] = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:44.295438Z","iopub.execute_input":"2025-04-22T04:41:44.295850Z","iopub.status.idle":"2025-04-22T04:41:44.305038Z","shell.execute_reply.started":"2025-04-22T04:41:44.295830Z","shell.execute_reply":"2025-04-22T04:41:44.304342Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df = pd.concat([df_pos, df_neg], ignore_index=True).sample(frac=1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:45.883116Z","iopub.execute_input":"2025-04-22T04:41:45.883409Z","iopub.status.idle":"2025-04-22T04:41:45.892731Z","shell.execute_reply.started":"2025-04-22T04:41:45.883381Z","shell.execute_reply":"2025-04-22T04:41:45.891952Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:47.194114Z","iopub.execute_input":"2025-04-22T04:41:47.194611Z","iopub.status.idle":"2025-04-22T04:41:47.208004Z","shell.execute_reply.started":"2025-04-22T04:41:47.194586Z","shell.execute_reply":"2025-04-22T04:41:47.207360Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_df.to_csv(\"train.csv\", index=False)\nval_df.to_csv(\"validation.csv\", index=False)\ntest_df.to_csv(\"test.csv\", index=False)\n\ntools.display_dataframe_to_user(\"Aggregated data with labels\", df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:49.120120Z","iopub.execute_input":"2025-04-22T04:41:49.120404Z","iopub.status.idle":"2025-04-22T04:41:49.770301Z","shell.execute_reply.started":"2025-04-22T04:41:49.120380Z","shell.execute_reply":"2025-04-22T04:41:49.769458Z"}},"outputs":[{"name":"stdout","text":"Aggregated data with labels\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table id=\"itables_b3c256c9_17a4_4795_b643_f27e1c853aad\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n<thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>label</th>\n    </tr>\n  </thead><tbody><tr>\n<td style=\"vertical-align:middle; text-align:left\">\n<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\nwidth=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n    <g style=\"fill:#d9d7fc\">\n        <path d=\"M100,400H500V357H100Z\" />\n        <path d=\"M100,300H400V257H100Z\" />\n        <path d=\"M0,200H400V157H0Z\" />\n        <path d=\"M100,100H500V57H100Z\" />\n        <path d=\"M100,350H500V307H100Z\" />\n        <path d=\"M100,250H400V207H100Z\" />\n        <path d=\"M0,150H400V107H0Z\" />\n        <path d=\"M100,50H500V7H100Z\" />\n    </g>\n    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;400;0\"\n      dur=\"5s\"\n      repeatCount=\"indefinite\" />\n      <animate\n      attributeName=\"x\"\n      values=\"100;100;500\"\n      dur=\"5s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;400;0\"\n      dur=\"3.5s\"\n      repeatCount=\"indefinite\" />\n    <animate\n      attributeName=\"x\"\n      values=\"0;0;400\"\n      dur=\"3.5s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;300;0\"\n      dur=\"3s\"\n      repeatCount=\"indefinite\" />\n    <animate\n      attributeName=\"x\"\n      values=\"100;100;400\"\n      dur=\"3s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;400;0\"\n      dur=\"4s\"\n      repeatCount=\"indefinite\" />\n      <animate\n      attributeName=\"x\"\n      values=\"100;100;500\"\n      dur=\"4s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n            <g transform=\"translate(45 50) rotate(-45)\">\n                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n            </g>\n\n            <g transform=\"translate(450 152)\">\n                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n            </g>\n\n            <g transform=\"translate(50 352)\">\n                <polygon points=\"-35,-5 0,-40 35,-5\" />\n                <polygon points=\"-35,10 0,45 35,10\" />\n            </g>\n\n            <g transform=\"translate(75 250)\">\n                <polyline points=\"-30,30 -60,0 -30,-30\" />\n                <polyline points=\"0,30 -30,0 0,-30\" />\n            </g>\n\n            <g transform=\"translate(425 250) rotate(180)\">\n                <polyline points=\"-30,30 -60,0 -30,-30\" />\n                <polyline points=\"0,30 -30,0 0,-30\" />\n            </g>\n        </g>\n    </g>\n</svg>\n</a>\nLoading ITables v2.3.0 from the internet...\n(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n</tr></tbody>\n</table>\n<link href=\"https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.css\" rel=\"stylesheet\">\n<script type=\"module\">\n    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.js';\n\n    document.querySelectorAll(\"#itables_b3c256c9_17a4_4795_b643_f27e1c853aad:not(.dataTable)\").forEach(table => {\n        if (!(table instanceof HTMLTableElement))\n            return;\n\n        // Define the table data\n        const data = [[3084, \"\\u0415\\u0441\\u043b\\u0438 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u043e\\u043c \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u043a\\u043e\\u043d\\u0446\\u0435\\u0441\\u0441\\u0438\\u0438 \\u043d\\u0435 \\u043f\\u0440\\u0435\\u0434\\u0443\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043d\\u043e \\u0438\\u043d\\u043e\\u0435, \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u044c \\u043e\\u0431\\u044f\\u0437\\u0430\\u043d: \\u043e\\u0431\\u0435\\u0441\\u043f\\u0435\\u0447\\u0438\\u0442\\u044c \\u0433\\u043e\\u0441\\u0443\\u0434\\u0430\\u0440\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u0443\\u044e \\u0440\\u0435\\u0433\\u0438\\u0441\\u0442\\u0440\\u0430\\u0446\\u0438\\u044e \\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u0435\\u043d\\u0438\\u044f \\u043f\\u0440\\u0430\\u0432\\u0430 \\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u0432 \\u043f\\u0440\\u0435\\u0434\\u043f\\u0440\\u0438\\u043d\\u0438\\u043c\\u0430\\u0442\\u0435\\u043b\\u044c\\u0441\\u043a\\u043e\\u0439 \\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u0438 \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u044f \\u043a\\u043e\\u043c\\u043f\\u043b\\u0435\\u043a\\u0441\\u0430 \\u043f\\u0440\\u0438\\u043d\\u0430\\u0434\\u043b\\u0435\\u0436\\u0430\\u0449\\u0438\\u0445 \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u044e \\u0438\\u0441\\u043a\\u043b\\u044e\\u0447\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445 \\u043f\\u0440\\u0430\\u0432 \\u043f\\u043e \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0443 \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u043a\\u043e\\u043d\\u0446\\u0435\\u0441\\u0441\\u0438\\u0438 ;  \\u043e\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u0442\\u044c \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u044e \\u043f\\u043e\\u0441\\u0442\\u043e\\u044f\\u043d\\u043d\\u043e\\u0435 \\u0442\\u0435\\u0445\\u043d\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0435 \\u0438 \\u043a\\u043e\\u043d\\u0441\\u0443\\u043b\\u044c\\u0442\\u0430\\u0442\\u0438\\u0432\\u043d\\u043e\\u0435 \\u0441\\u043e\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0435, \\u0432\\u043a\\u043b\\u044e\\u0447\\u0430\\u044f \\u0441\\u043e\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0435 \\u0432 \\u043e\\u0431\\u0443\\u0447\\u0435\\u043d\\u0438\\u0438 \\u0438 \\u043f\\u043e\\u0432\\u044b\\u0448\\u0435\\u043d\\u0438\\u0438 \\u043a\\u0432\\u0430\\u043b\\u0438\\u0444\\u0438\\u043a\\u0430\\u0446\\u0438\\u0438 \\u0440\\u0430\\u0431\\u043e\\u0442\\u043d\\u0438\\u043a\\u043e\\u0432; \\u043a\\u043e\\u043d\\u0442\\u0440\\u043e\\u043b\\u0438\\u0440\\u043e\\u0432\\u0430\\u0442\\u044c \\u043a\\u0430\\u0447\\u0435\\u0441\\u0442\\u0432\\u043e \\u0442\\u043e\\u0432\\u0430\\u0440\\u043e\\u0432 , \\u043f\\u0440\\u043e\\u0438\\u0437\\u0432\\u043e\\u0434\\u0438\\u043c\\u044b\\u0445 \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0435\\u043c \\u043d\\u0430 \\u043e\\u0441\\u043d\\u043e\\u0432\\u0430\\u043d\\u0438\\u0438 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u043a\\u043e\\u043d\\u0446\\u0435\\u0441\\u0441\\u0438\\u0438. \\u0421 \\u0443\\u0447\\u0435\\u0442\\u043e\\u043c \\u0445\\u0430\\u0440\\u0430\\u043a\\u0442\\u0435\\u0440\\u0430 \\u0438 \\u043e\\u0441\\u043e\\u0431\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u0435\\u0439 \\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u0438, \\u043e\\u0441\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u043b\\u044f\\u0435\\u043c\\u043e\\u0439 \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0435\\u043c \\u043f\\u043e \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0443 \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u043a\\u043e\\u043d\\u0446\\u0435\\u0441\\u0441\\u0438\\u0438, \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u044c \\u043e\\u0431\\u044f\\u0437\\u0430\\u043d: \\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u044c \\u043f\\u0440\\u0438 \\u043e\\u0441\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u043b\\u0435\\u043d\\u0438\\u0438 \\u043f\\u0440\\u0435\\u0434\\u0443\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043d\\u043d\\u043e\\u0439 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u043e\\u043c \\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u0438 \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0435 \\u043e\\u0431\\u043e\\u0437\\u043d\\u0430\\u0447\\u0435\\u043d\\u0438\\u0435, \\u0442\\u043e\\u0432\\u0430\\u0440\\u043d\\u044b\\u0439 \\u0437\\u043d\\u0430\\u043a, \\u0437\\u043d\\u0430\\u043a \\u043e\\u0431\\u0441\\u043b\\u0443\\u0436\\u0438\\u0432\\u0430\\u043d\\u0438\\u044f \\u0438\\u043b\\u0438 \\u0438\\u043d\\u043e\\u0435 \\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u043e \\u0438\\u043d\\u0434\\u0438\\u0432\\u0438\\u0434\\u0443\\u0430\\u043b\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u044f \\u0443\\u043a\\u0430\\u0437\\u0430\\u043d\\u043d\\u044b\\u043c \\u0432 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0435 \\u043e\\u0431\\u0440\\u0430\\u0437\\u043e\\u043c;  \\u043e\\u0431\\u0435\\u0441\\u043f\\u0435\\u0447\\u0438\\u0432\\u0430\\u0442\\u044c \\u0441\\u043e\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0438\\u0435 \\u043a\\u0430\\u0447\\u0435\\u0441\\u0442\\u0432\\u0430 \\u043f\\u0440\\u043e\\u0438\\u0437\\u0432\\u043e\\u0434\\u0438\\u043c\\u044b\\u0445 \\u0438\\u043c \\u043d\\u0430 \\u043e\\u0441\\u043d\\u043e\\u0432\\u0435 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u0442\\u043e\\u0432\\u0430\\u0440\\u043e\\u0432, \\u0432\\u044b\\u043f\\u043e\\u043b\\u043d\\u044f\\u0435\\u043c\\u044b\\u0445 \\u0440\\u0430\\u0431\\u043e\\u0442, \\u043e\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u0435\\u043c\\u044b\\u0445 \\u0443\\u0441\\u043b\\u0443\\u0433 \\u043a\\u0430\\u0447\\u0435\\u0441\\u0442\\u0432\\u0443 \\u0430\\u043d\\u0430\\u043b\\u043e\\u0433\\u0438\\u0447\\u043d\\u044b\\u0445 \\u0442\\u043e\\u0432\\u0430\\u0440\\u043e\\u0432, \\u0440\\u0430\\u0431\\u043e\\u0442 \\u0438\\u043b\\u0438 \\u0443\\u0441\\u043b\\u0443\\u0433, \\u043f\\u0440\\u043e\\u0438\\u0437\\u0432\\u043e\\u0434\\u0438\\u043c\\u044b\\u0445, \\u0432\\u044b\\u043f\\u043e\\u043b\\u043d\\u044f\\u0435\\u043c\\u044b\\u0445 \\u0438\\u043b\\u0438 \\u043e\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u0435\\u043c\\u044b\\u0445 \\u043d\\u0435\\u043f\\u043e\\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u0435\\u043c; \\u0441\\u043e\\u0431\\u043b\\u044e\\u0434\\u0430\\u0442\\u044c \\u0438\\u043d\\u0441\\u0442\\u0440\\u0443\\u043a\\u0446\\u0438\\u0438 \\u0438 \\u0443\\u043a\\u0430\\u0437\\u0430\\u043d\\u0438\\u044f \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u044f, \\u043d\\u0430\\u043f\\u0440\\u0430\\u0432\\u043b\\u0435\\u043d\\u043d\\u044b\\u0435 \\u043d\\u0430 \\u043e\\u0431\\u0435\\u0441\\u043f\\u0435\\u0447\\u0435\\u043d\\u0438\\u0435 \\u0441\\u043e\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0438\\u044f \\u0445\\u0430\\u0440\\u0430\\u043a\\u0442\\u0435\\u0440\\u0430, \\u0441\\u043f\\u043e\\u0441\\u043e\\u0431\\u043e\\u0432 \\u0438 \\u0443\\u0441\\u043b\\u043e\\u0432\\u0438\\u0439 \\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043a\\u043e\\u043c\\u043f\\u043b\\u0435\\u043a\\u0441\\u0430 \\u0438\\u0441\\u043a\\u043b\\u044e\\u0447\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0445 \\u043f\\u0440\\u0430\\u0432 \\u0442\\u043e\\u043c\\u0443, \\u043a\\u0430\\u043a \\u043e\\u043d \\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u0443\\u0435\\u0442\\u0441\\u044f \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u0435\\u043c, \\u0432 \\u0442\\u043e\\u043c \\u0447\\u0438\\u0441\\u043b\\u0435 \\u0443\\u043a\\u0430\\u0437\\u0430\\u043d\\u0438\\u044f, \\u043a\\u0430\\u0441\\u0430\\u044e\\u0449\\u0438\\u0435\\u0441\\u044f \\u0432\\u043d\\u0435\\u0448\\u043d\\u0435\\u0433\\u043e \\u0438 \\u0432\\u043d\\u0443\\u0442\\u0440\\u0435\\u043d\\u043d\\u0435\\u0433\\u043e \\u043e\\u0444\\u043e\\u0440\\u043c\\u043b\\u0435\\u043d\\u0438\\u044f \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u0438\\u0445 \\u043f\\u043e\\u043c\\u0435\\u0449\\u0435\\u043d\\u0438\\u0439, \\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u0443\\u0435\\u043c\\u044b\\u0445 \\u043f\\u043e\\u043b\\u044c\\u0437\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u0435\\u043c \\u043f\\u0440\\u0438 \\u043e\\u0441\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u043b\\u0435\\u043d\\u0438\\u0438 \\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u0435\\u043d\\u043d\\u044b\\u0445 \\u0435\\u043c\\u0443 \\u043f\\u043e \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0443 \\u043f\\u0440\\u0430\\u0432; \\u043e\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u0442\\u044c \\u043f\\u043e\\u043a\\u0443\\u043f\\u0430\\u0442\\u0435\\u043b\\u044f\\u043c  \\u0432\\u0441\\u0435 \\u0434\\u043e\\u043f\\u043e\\u043b\\u043d\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u044b\\u0435 \\u0443\\u0441\\u043b\\u0443\\u0433\\u0438, \\u043d\\u0430 \\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435 \\u043e\\u043d\\u0438 \\u043c\\u043e\\u0433\\u043b\\u0438 \\u0431\\u044b \\u0440\\u0430\\u0441\\u0441\\u0447\\u0438\\u0442\\u044b\\u0432\\u0430\\u0442\\u044c, \\u043f\\u0440\\u0438\\u043e\\u0431\\u0440\\u0435\\u0442\\u0430\\u044f  \\u0442\\u043e\\u0432\\u0430\\u0440  \\u043d\\u0435\\u043f\\u043e\\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e \\u0443 \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u044f; \\u043d\\u0435 \\u0440\\u0430\\u0437\\u0433\\u043b\\u0430\\u0448\\u0430\\u0442\\u044c \\u0441\\u0435\\u043a\\u0440\\u0435\\u0442\\u044b \\u043f\\u0440\\u043e\\u0438\\u0437\\u0432\\u043e\\u0434\\u0441\\u0442\\u0432\\u0430  \\u043f\\u0440\\u0430\\u0432\\u043e\\u043e\\u0431\\u043b\\u0430\\u0434\\u0430\\u0442\\u0435\\u043b\\u044f \\u0438 \\u0434\\u0440\\u0443\\u0433\\u0443\\u044e \\u043f\\u043e\\u043b\\u0443\\u0447\\u0435\\u043d\\u043d\\u0443\\u044e \\u043e\\u0442 \\u043d\\u0435\\u0433\\u043e \\u043a\\u043e\\u043d\\u0444\\u0438\\u0434\\u0435\\u043d\\u0446\\u0438\\u0430\\u043b\\u044c\\u043d\\u0443\\u044e \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u0443\\u044e \\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u044e;  \\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u0438\\u0442\\u044c \\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0435\\u043d\\u043d\\u043e\\u0435 \\u043a\\u043e\\u043b\\u0438\\u0447\\u0435\\u0441\\u0442\\u0432\\u043e \\u0441\\u0443\\u0431\\u043a\\u043e\\u043d\\u0446\\u0435\\u0441\\u0441\\u0438\\u0439, \\u0435\\u0441\\u043b\\u0438 \\u0442\\u0430\\u043a\\u0430\\u044f \\u043e\\u0431\\u044f\\u0437\\u0430\\u043d\\u043d\\u043e\\u0441\\u0442\\u044c \\u043f\\u0440\\u0435\\u0434\\u0443\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043d\\u0430 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u043e\\u043c; \\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u0442\\u044c \\u043f\\u043e\\u043a\\u0443\\u043f\\u0430\\u0442\\u0435\\u043b\\u0435\\u0439  \\u043d\\u0430\\u0438\\u0431\\u043e\\u043b\\u0435\\u0435 \\u043e\\u0447\\u0435\\u0432\\u0438\\u0434\\u043d\\u044b\\u043c \\u0434\\u043b\\u044f \\u043d\\u0438\\u0445 \\u0441\\u043f\\u043e\\u0441\\u043e\\u0431\\u043e\\u043c \\u043e \\u0442\\u043e\\u043c, \\u0447\\u0442\\u043e \\u043e\\u043d \\u0438\\u0441\\u043f\\u043e\\u043b\\u044c\\u0437\\u0443\\u0435\\u0442 \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0435 \\u043e\\u0431\\u043e\\u0437\\u043d\\u0430\\u0447\\u0435\\u043d\\u0438\\u0435, \\u0442\\u043e\\u0432\\u0430\\u0440\\u043d\\u044b\\u0439 \\u0437\\u043d\\u0430\\u043a, \\u0437\\u043d\\u0430\\u043a \\u043e\\u0431\\u0441\\u043b\\u0443\\u0436\\u0438\\u0432\\u0430\\u043d\\u0438\\u044f \\u0438\\u043b\\u0438 \\u0438\\u043d\\u043e\\u0435 \\u0441\\u0440\\u0435\\u0434\\u0441\\u0442\\u0432\\u043e \\u0438\\u043d\\u0434\\u0438\\u0432\\u0438\\u0434\\u0443\\u0430\\u043b\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u0432 \\u0441\\u0438\\u043b\\u0443 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u043a\\u043e\\u043c\\u043c\\u0435\\u0440\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u043a\\u043e\\u043d\\u0446\\u0435\\u0441\\u0441\\u0438\\u0438.\", 1], [134, \"\\u041f\\u0430\\u0442\\u0440\\u043e\\u043d\\u0430\\u0436 \\u043d\\u0430\\u0434 \\u0441\\u043e\\u0432\\u0435\\u0440\\u0448\\u0435\\u043d\\u043d\\u043e\\u043b\\u0435\\u0442\\u043d\\u0438\\u043c \\u0434\\u0435\\u0435\\u0441\\u043f\\u043e\\u0441\\u043e\\u0431\\u043d\\u044b\\u043c \\u0433\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\\u0438\\u043d\\u043e\\u043c, \\u0443\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u043b\\u0435\\u043d\\u043d\\u044b\\u0439 \\u0432 \\u0441\\u043e\\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0438\\u0438 \\u0441 \\u043f\\u0443\\u043d\\u043a\\u0442\\u043e\\u043c 1 \\u043d\\u0430\\u0441\\u0442\\u043e\\u044f\\u0449\\u0435\\u0439 \\u0441\\u0442\\u0430\\u0442\\u044c\\u0438, \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0449\\u0430\\u0435\\u0442\\u0441\\u044f \\u0432 \\u0441\\u0432\\u044f\\u0437\\u0438 \\u0441 \\u043f\\u0440\\u0435\\u043a\\u0440\\u0430\\u0449\\u0435\\u043d\\u0438\\u0435\\u043c \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u043f\\u043e\\u0440\\u0443\\u0447\\u0435\\u043d\\u0438\\u044f, \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u0434\\u043e\\u0432\\u0435\\u0440\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0433\\u043e \\u0443\\u043f\\u0440\\u0430\\u0432\\u043b\\u0435\\u043d\\u0438\\u044f \\u0438\\u043c\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u043e\\u043c \\u0438\\u043b\\u0438 \\u0438\\u043d\\u043e\\u0433\\u043e \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u043f\\u043e \\u043e\\u0441\\u043d\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f\\u043c, \\u043f\\u0440\\u0435\\u0434\\u0443\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043d\\u043d\\u044b\\u043c \\u0437\\u0430\\u043a\\u043e\\u043d\\u043e\\u043c \\u0438\\u043b\\u0438 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u043e\\u043c. \\u0413\\u0440\\u0430\\u0436\\u0434\\u0430\\u043d\\u0438\\u043d \\u043c\\u043e\\u0436\\u0435\\u0442 \\u0431\\u044b\\u0442\\u044c \\u043f\\u043e \\u0437\\u0430\\u044f\\u0432\\u043b\\u0435\\u043d\\u0438\\u044e \\u0437\\u0430\\u0438\\u043d\\u0442\\u0435\\u0440\\u0435\\u0441\\u043e\\u0432\\u0430\\u043d\\u043d\\u044b\\u0445 \\u043b\\u0438\\u0446 \\u043f\\u0440\\u0438\\u0437\\u043d\\u0430\\u043d \\u0441\\u0443\\u0434\\u043e\\u043c \\u0431\\u0435\\u0437\\u0432\\u0435\\u0441\\u0442\\u043d\\u043e \\u043e\\u0442\\u0441\\u0443\\u0442\\u0441\\u0442\\u0432\\u0443\\u044e\\u0449\\u0438\\u043c, \\u0435\\u0441\\u043b\\u0438 \\u0432 \\u0442\\u0435\\u0447\\u0435\\u043d\\u0438\\u0435 \\u0433\\u043e\\u0434\\u0430 \\u0432 \\u043c\\u0435\\u0441\\u0442\\u0435 \\u0435\\u0433\\u043e \\u0436\\u0438\\u0442\\u0435\\u043b\\u044c\\u0441\\u0442\\u0432\\u0430 \\u043d\\u0435\\u0442 \\u0441\\u0432\\u0435\\u0434\\u0435\\u043d\\u0438\\u0439 \\u043e \\u043c\\u0435\\u0441\\u0442\\u0435 \\u0435\\u0433\\u043e \\u043f\\u0440\\u0435\\u0431\\u044b\\u0432\\u0430\\u043d\\u0438\\u044f. \\u041f\\u0440\\u0438 \\u043d\\u0435\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e\\u0441\\u0442\\u0438 \\u0443\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u0442\\u044c \\u0434\\u0435\\u043d\\u044c \\u043f\\u043e\\u043b\\u0443\\u0447\\u0435\\u043d\\u0438\\u044f \\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0445 \\u0441\\u0432\\u0435\\u0434\\u0435\\u043d\\u0438\\u0439 \\u043e\\u0431 \\u043e\\u0442\\u0441\\u0443\\u0442\\u0441\\u0442\\u0432\\u0443\\u044e\\u0449\\u0435\\u043c \\u043d\\u0430\\u0447\\u0430\\u043b\\u043e\\u043c \\u0438\\u0441\\u0447\\u0438\\u0441\\u043b\\u0435\\u043d\\u0438\\u044f \\u0441\\u0440\\u043e\\u043a\\u0430 \\u0434\\u043b\\u044f \\u043f\\u0440\\u0438\\u0437\\u043d\\u0430\\u043d\\u0438\\u044f \\u0431\\u0435\\u0437\\u0432\\u0435\\u0441\\u0442\\u043d\\u043e\\u0433\\u043e \\u043e\\u0442\\u0441\\u0443\\u0442\\u0441\\u0442\\u0432\\u0438\\u044f \\u0441\\u0447\\u0438\\u0442\\u0430\\u0435\\u0442\\u0441\\u044f \\u043f\\u0435\\u0440\\u0432\\u043e\\u0435 \\u0447\\u0438\\u0441\\u043b\\u043e \\u043c\\u0435\\u0441\\u044f\\u0446\\u0430, \\u0441\\u043b\\u0435\\u0434\\u0443\\u044e\\u0449\\u0435\\u0433\\u043e \\u0437\\u0430 \\u0442\\u0435\\u043c, \\u0432 \\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u043c \\u0431\\u044b\\u043b\\u0438 \\u043f\\u043e\\u043b\\u0443\\u0447\\u0435\\u043d\\u044b \\u043f\\u043e\\u0441\\u043b\\u0435\\u0434\\u043d\\u0438\\u0435 \\u0441\\u0432\\u0435\\u0434\\u0435\\u043d\\u0438\\u044f \\u043e\\u0431 \\u043e\\u0442\\u0441\\u0443\\u0442\\u0441\\u0442\\u0432\\u0443\\u044e\\u0449\\u0435\\u043c, \\u0430 \\u043f\\u0440\\u0438 \\u043d\\u0435\\u0432\\u043e\\u0437\\u043c\\u043e\\u0436\\u043d\\u043e\\u0441\\u0442\\u0438 \\u0443\\u0441\\u0442\\u0430\\u043d\\u043e\\u0432\\u0438\\u0442\\u044c \\u044d\\u0442\\u043e\\u0442 \\u043c\\u0435\\u0441\\u044f\\u0446 - \\u043f\\u0435\\u0440\\u0432\\u043e\\u0435 \\u044f\\u043d\\u0432\\u0430\\u0440\\u044f \\u0441\\u043b\\u0435\\u0434\\u0443\\u044e\\u0449\\u0435\\u0433\\u043e \\u0433\\u043e\\u0434\\u0430.\", 1], [411, \"\\u0423\\u0441\\u0442\\u0430\\u0432\\u043d\\u044b\\u0439 \\u043a\\u0430\\u043f\\u0438\\u0442\\u0430\\u043b \\u043e\\u0431\\u0449\\u0435\\u0441\\u0442\\u0432\\u0430 \\u0441 \\u043e\\u0433\\u0440\\u0430\\u043d\\u0438\\u0447\\u0435\\u043d\\u043d\\u043e\\u0439 \\u043e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u044c\\u044e  \\u0441\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f \\u0438\\u0437 \\u043d\\u043e\\u043c\\u0438\\u043d\\u0430\\u043b\\u044c\\u043d\\u043e\\u0439 \\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u0438 \\u0434\\u043e\\u043b\\u0435\\u0439 \\u0443\\u0447\\u0430\\u0441\\u0442\\u043d\\u0438\\u043a\\u043e\\u0432.\", 1], [203, \"\\u041e\\u0442\\u0432\\u0435\\u0442\\u0441\\u0442\\u0432\\u0435\\u043d\\u043d\\u043e\\u0441\\u0442\\u044c, \\u043f\\u0440\\u0435\\u0434\\u0443\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043d\\u043d\\u0443\\u044e \\u043f\\u0443\\u043d\\u043a\\u0442\\u043e\\u043c 1 \\u043d\\u0430\\u0441\\u0442\\u043e\\u044f\\u0449\\u0435\\u0439 \\u0441\\u0442\\u0430\\u0442\\u044c\\u0438, \\u043d\\u0435\\u0441\\u0443\\u0442 \\u0442\\u0430\\u043a\\u0436\\u0435 \\u0447\\u043b\\u0435\\u043d\\u044b \\u043a\\u043e\\u043b\\u043b\\u0435\\u0433\\u0438\\u0430\\u043b\\u044c\\u043d\\u044b\\u0445 \\u043e\\u0440\\u0433\\u0430\\u043d\\u043e\\u0432 \\u044e\\u0440\\u0438\\u0434\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0433\\u043e \\u043b\\u0438\\u0446\\u0430, \\u0437\\u0430 \\u0438\\u0441\\u043a\\u043b\\u044e\\u0447\\u0435\\u043d\\u0438\\u0435\\u043c \\u0442\\u0435\\u0445 \\u0438\\u0437 \\u043d\\u0438\\u0445, \\u043a\\u0442\\u043e \\u0433\\u043e\\u043b\\u043e\\u0441\\u043e\\u0432\\u0430\\u043b \\u043f\\u0440\\u043e\\u0442\\u0438\\u0432 \\u0440\\u0435\\u0448\\u0435\\u043d\\u0438\\u044f, \\u043a\\u043e\\u0442\\u043e\\u0440\\u043e\\u0435 \\u043f\\u043e\\u0432\\u043b\\u0435\\u043a\\u043b\\u043e \\u043f\\u0440\\u0438\\u0447\\u0438\\u043d\\u0435\\u043d\\u0438\\u0435 \\u044e\\u0440\\u0438\\u0434\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u043c\\u0443 \\u043b\\u0438\\u0446\\u0443 \\u0443\\u0431\\u044b\\u0442\\u043a\\u043e\\u0432, \\u0438\\u043b\\u0438, \\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0443\\u044f \\u0434\\u043e\\u0431\\u0440\\u043e\\u0441\\u043e\\u0432\\u0435\\u0441\\u0442\\u043d\\u043e, \\u043d\\u0435 \\u043f\\u0440\\u0438\\u043d\\u0438\\u043c\\u0430\\u043b \\u0443\\u0447\\u0430\\u0441\\u0442\\u0438\\u044f \\u0432 \\u0433\\u043e\\u043b\\u043e\\u0441\\u043e\\u0432\\u0430\\u043d\\u0438\\u0438.\", 1], [2938, \"\\u041f\\u0440\\u0438 \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u043d\\u0438\\u0438 \\u0438\\u043c\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u0430 \\u0438\\u043b\\u0438 \\u043f\\u0440\\u0435\\u0434\\u043f\\u0440\\u0438\\u043d\\u0438\\u043c\\u0430\\u0442\\u0435\\u043b\\u044c\\u0441\\u043a\\u043e\\u0433\\u043e \\u0440\\u0438\\u0441\\u043a\\u0430, \\u0435\\u0441\\u043b\\u0438 \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u043e\\u043c \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f \\u043d\\u0435 \\u043f\\u0440\\u0435\\u0434\\u0443\\u0441\\u043c\\u043e\\u0442\\u0440\\u0435\\u043d\\u043e \\u0438\\u043d\\u043e\\u0435, \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u044f \\u0441\\u0443\\u043c\\u043c\\u0430 \\u043d\\u0435 \\u0434\\u043e\\u043b\\u0436\\u043d\\u0430 \\u043f\\u0440\\u0435\\u0432\\u044b\\u0448\\u0430\\u0442\\u044c \\u0438\\u0445 \\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u0443\\u044e \\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c . \\u0422\\u0430\\u043a\\u043e\\u0439 \\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c\\u044e \\u0441\\u0447\\u0438\\u0442\\u0430\\u0435\\u0442\\u0441\\u044f: \\u0434\\u043b\\u044f \\u0438\\u043c\\u0443\\u0449\\u0435\\u0441\\u0442\\u0432\\u0430 \\u0435\\u0433\\u043e \\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u0442\\u0435\\u043b\\u044c\\u043d\\u0430\\u044f \\u0441\\u0442\\u043e\\u0438\\u043c\\u043e\\u0441\\u0442\\u044c \\u0432 \\u043c\\u0435\\u0441\\u0442\\u0435 \\u0435\\u0433\\u043e \\u043d\\u0430\\u0445\\u043e\\u0436\\u0434\\u0435\\u043d\\u0438\\u044f \\u0432 \\u0434\\u0435\\u043d\\u044c \\u0437\\u0430\\u043a\\u043b\\u044e\\u0447\\u0435\\u043d\\u0438\\u044f \\u0434\\u043e\\u0433\\u043e\\u0432\\u043e\\u0440\\u0430 \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u043d\\u0438\\u044f; \\u0434\\u043b\\u044f \\u043f\\u0440\\u0435\\u0434\\u043f\\u0440\\u0438\\u043d\\u0438\\u043c\\u0430\\u0442\\u0435\\u043b\\u044c\\u0441\\u043a\\u043e\\u0433\\u043e \\u0440\\u0438\\u0441\\u043a\\u0430 \\u0443\\u0431\\u044b\\u0442\\u043a\\u0438 \\u043e\\u0442 \\u043f\\u0440\\u0435\\u0434\\u043f\\u0440\\u0438\\u043d\\u0438\\u043c\\u0430\\u0442\\u0435\\u043b\\u044c\\u0441\\u043a\\u043e\\u0439 \\u0434\\u0435\\u044f\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\\u0441\\u0442\\u0438, \\u043a\\u043e\\u0442\\u043e\\u0440\\u044b\\u0435 \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u0430\\u0442\\u0435\\u043b\\u044c, \\u043a\\u0430\\u043a \\u043c\\u043e\\u0436\\u043d\\u043e \\u043e\\u0436\\u0438\\u0434\\u0430\\u0442\\u044c, \\u043f\\u043e\\u043d\\u0435\\u0441 \\u0431\\u044b \\u043f\\u0440\\u0438 \\u043d\\u0430\\u0441\\u0442\\u0443\\u043f\\u043b\\u0435\\u043d\\u0438\\u0438 \\u0441\\u0442\\u0440\\u0430\\u0445\\u043e\\u0432\\u043e\\u0433\\u043e \\u0441\\u043b\\u0443\\u0447\\u0430\\u044f.\", 1]];\n\n        // Define the dt_args\n        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n        dt_args[\"data\"] = data;\n\n        \n        new DataTable(table, dt_args);\n    });\n</script>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:52.227069Z","iopub.execute_input":"2025-04-22T04:41:52.227484Z","iopub.status.idle":"2025-04-22T04:41:52.238320Z","shell.execute_reply.started":"2025-04-22T04:41:52.227462Z","shell.execute_reply":"2025-04-22T04:41:52.237774Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                   Text  label\n902   Решение собрания может быть признано судом нед...      1\n1267  Если каждая из сторон по договору несет обязан...      1\n2856  По договору условного депонирования  депонент ...      1\n845   За исключением случаев, предусмотренных пункто...      1\n977   Если законом не установлено иное, течение срок...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>902</th>\n      <td>Решение собрания может быть признано судом нед...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1267</th>\n      <td>Если каждая из сторон по договору несет обязан...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2856</th>\n      <td>По договору условного депонирования  депонент ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>За исключением случаев, предусмотренных пункто...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>Если законом не установлено иное, течение срок...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, BitsAndBytesConfig, T5ForConditionalGeneration, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport torch\nfrom peft import LoraConfig, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:41:55.019298Z","iopub.execute_input":"2025-04-22T04:41:55.019596Z","iopub.status.idle":"2025-04-22T04:42:18.850374Z","shell.execute_reply.started":"2025-04-22T04:41:55.019572Z","shell.execute_reply":"2025-04-22T04:42:18.849816Z"}},"outputs":[{"name":"stderr","text":"2025-04-22 04:42:06.503729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745296926.695654      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745296926.748393      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install peft datasets --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:45:43.159180Z","iopub.execute_input":"2025-04-22T04:45:43.159915Z","iopub.status.idle":"2025-04-22T04:46:53.459814Z","shell.execute_reply.started":"2025-04-22T04:45:43.159893Z","shell.execute_reply":"2025-04-22T04:46:53.459066Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/8a/6d/44ad094874c6f1b9c654f8ed939590bdc408349f137f9b98a3a23ccec411/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/3a/e1/5b9089a4b2a4790dfdea8b3a006052cfecff58139d5a4e34cb1a51df8d6f/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"data_files = {\"train\": \"train.csv\", \"validation\": \"validation.csv\"}\nraw_datasets = load_dataset(\"csv\", data_files=data_files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:03.646951Z","iopub.execute_input":"2025-04-22T04:47:03.647751Z","iopub.status.idle":"2025-04-22T04:47:03.920073Z","shell.execute_reply.started":"2025-04-22T04:47:03.647722Z","shell.execute_reply":"2025-04-22T04:47:03.919579Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf78ea419714b3c9dc5d27b4b65b210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e17019f7a11e4679998547047cdd8d9a"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model_name = \"t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nbnb_config = BitsAndBytesConfig(load_in_8bit=True)\n\n\nbase_model = T5ForConditionalGeneration.from_pretrained(\n    \"t5-small\",\n    device_map={\"\": \"cpu\"},\n    torch_dtype=torch.float16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:05.704052Z","iopub.execute_input":"2025-04-22T04:47:05.704586Z","iopub.status.idle":"2025-04-22T04:47:08.411826Z","shell.execute_reply.started":"2025-04-22T04:47:05.704554Z","shell.execute_reply":"2025-04-22T04:47:08.411039Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30bdaa6d3c9d4f6db91a9fa5d4863c0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7980d915f44b3691f5dbb13d0f0f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c3fb8d5c488428e99e1d69ab5bd38f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3fe44f6947e4f738c8e8a605dbbae2c"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05fda34a743946f6a462d10c561fc672"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3d62dcb83b84769bea838157ea25f3e"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"lora_config = LoraConfig(\n    task_type=\"SEQ_2_SEQ_LM\", \n    r=8, \n    lora_alpha=16,\n    target_modules=[\"q\",\"v\"], \n    lora_dropout=0.05\n)\n\nmodel = get_peft_model(base_model, lora_config)\n\nmodel = model.to(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:10.428813Z","iopub.execute_input":"2025-04-22T04:47:10.429424Z","iopub.status.idle":"2025-04-22T04:47:10.698988Z","shell.execute_reply.started":"2025-04-22T04:47:10.429401Z","shell.execute_reply":"2025-04-22T04:47:10.698402Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def preprocess_fn(examples):\n    inputs = [\"Classify text as legal or non-legal: \" + txt for txt in examples[\"Text\"]]\n    targets = [\"legal\" if lab == 1 else \"non-legal\" for lab in examples[\"label\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=4, truncation=True, padding=\"max_length\")\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = raw_datasets.map(preprocess_fn, batched=True, remove_columns=[\"Text\", \"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:11.883332Z","iopub.execute_input":"2025-04-22T04:47:11.883622Z","iopub.status.idle":"2025-04-22T04:47:13.805483Z","shell.execute_reply.started":"2025-04-22T04:47:11.883602Z","shell.execute_reply":"2025-04-22T04:47:13.804896Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2615 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4358b6e1a9614ea89be5b8843310cd0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/327 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3c6cf92fbe340ffb2f08049e2dd4604"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:15.509329Z","iopub.execute_input":"2025-04-22T04:47:15.509700Z","iopub.status.idle":"2025-04-22T04:47:15.513792Z","shell.execute_reply.started":"2025-04-22T04:47:15.509677Z","shell.execute_reply":"2025-04-22T04:47:15.513043Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"lora_t5_classifier\",\n    num_train_epochs=10,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=2,\n    logging_steps=50,\n    logging_first_step=True,\n    do_train=True,\n    do_eval=True,\n    eval_steps=100,\n    save_steps=100,\n    save_strategy=\"epoch\", \n    save_total_limit=2,\n    learning_rate=5e-5,\n    predict_with_generate=True,\n    report_to=[]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:17.353153Z","iopub.execute_input":"2025-04-22T04:47:17.353745Z","iopub.status.idle":"2025-04-22T04:47:17.381416Z","shell.execute_reply.started":"2025-04-22T04:47:17.353716Z","shell.execute_reply":"2025-04-22T04:47:17.380649Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:19.311198Z","iopub.execute_input":"2025-04-22T04:47:19.311806Z","iopub.status.idle":"2025-04-22T04:47:19.331375Z","shell.execute_reply.started":"2025-04-22T04:47:19.311781Z","shell.execute_reply":"2025-04-22T04:47:19.330841Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/3607913767.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nNo label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import time\n\nstart_time = time.time()\ntrainer.train()\nend_time = time.time()\nprint(f\"\\n Время обучения: {(end_time - start_time)/60:.2f} минут\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:47:21.793033Z","iopub.execute_input":"2025-04-22T04:47:21.793583Z","iopub.status.idle":"2025-04-22T04:56:56.474237Z","shell.execute_reply.started":"2025-04-22T04:47:21.793559Z","shell.execute_reply":"2025-04-22T04:56:56.473661Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3270' max='3270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3270/3270 09:33, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>17.609400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>16.982600</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>14.574900</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>10.994100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>7.307500</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>4.382500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.636100</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.344800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.789600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.528300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.401300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.264600</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.281500</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.206000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.211100</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.141100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.108500</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.132200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.094300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.121100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.123700</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.098300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.078200</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.047200</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.098500</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.088600</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.044200</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.080500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.053100</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.059200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.089000</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.060600</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.036500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.057000</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.081300</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.057200</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.024000</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.067700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.049300</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.046600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.035700</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.043800</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.047100</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.054900</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.053700</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.061200</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.049100</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.055400</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.019700</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.044300</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.048200</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.022500</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.058000</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.061500</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.031900</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.063100</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.052100</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.059000</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.039300</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.028100</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.024300</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>0.028400</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.052800</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>0.041000</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.040800</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.039300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\n Время обучения: 9.58 минут\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import subprocess\nfrom IPython.display import FileLink, display\n\ndef download_file(path, download_file_name):\n    os.chdir('/kaggle/working/')\n    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n    command = f\"zip {zip_name} {path} -r\"\n    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(\"Unable to run zip command!\")\n        print(result.stderr)\n        return\n    display(FileLink(f'{download_file_name}.zip'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:59:34.446599Z","iopub.execute_input":"2025-04-22T03:59:34.447229Z","iopub.status.idle":"2025-04-22T03:59:34.451740Z","shell.execute_reply.started":"2025-04-22T03:59:34.447205Z","shell.execute_reply":"2025-04-22T03:59:34.451175Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"download_file('/kaggle/working/SimPO/__MACOSX', 'out')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T03:59:36.056514Z","iopub.execute_input":"2025-04-22T03:59:36.056792Z","iopub.status.idle":"2025-04-22T03:59:36.066015Z","shell.execute_reply.started":"2025-04-22T03:59:36.056772Z","shell.execute_reply":"2025-04-22T03:59:36.065307Z"}},"outputs":[{"name":"stdout","text":"Unable to run zip command!\n\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"model.save_pretrained(\"lora_t5_classifier\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade transformers bitsandbytes peft datasets --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nfrom peft import PeftConfig, PeftModel\nimport torch\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration\nfrom peft import PeftModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:57:20.431876Z","iopub.execute_input":"2025-04-22T04:57:20.432137Z","iopub.status.idle":"2025-04-22T04:57:20.436266Z","shell.execute_reply.started":"2025-04-22T04:57:20.432120Z","shell.execute_reply":"2025-04-22T04:57:20.435525Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/working/SimPO/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:57:22.267170Z","iopub.execute_input":"2025-04-22T04:57:22.267415Z","iopub.status.idle":"2025-04-22T04:57:22.276911Z","shell.execute_reply.started":"2025-04-22T04:57:22.267400Z","shell.execute_reply":"2025-04-22T04:57:22.276306Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\nbase_model = T5ForConditionalGeneration.from_pretrained(\n    \"t5-small\",\n    device_map={\"\": \"cpu\"},\n    torch_dtype=torch.float16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:57:23.627468Z","iopub.execute_input":"2025-04-22T04:57:23.627729Z","iopub.status.idle":"2025-04-22T04:57:24.081045Z","shell.execute_reply.started":"2025-04-22T04:57:23.627712Z","shell.execute_reply":"2025-04-22T04:57:24.080289Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\nos.environ[\"NCCL_IB_DISABLE\"] = \"1\"\nos.environ[\"CUDA_MODULE_LOADING\"] = \"LAZY\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:57:26.494746Z","iopub.execute_input":"2025-04-22T04:57:26.494994Z","iopub.status.idle":"2025-04-22T04:57:26.498677Z","shell.execute_reply.started":"2025-04-22T04:57:26.494979Z","shell.execute_reply":"2025-04-22T04:57:26.497974Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"adapter_dir = \"/kaggle/working/SimPO/lora_t5_classifier/checkpoint-3270\"\nconfig = PeftConfig.from_pretrained(adapter_dir, local_files_only=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:57:57.287472Z","iopub.execute_input":"2025-04-22T04:57:57.287791Z","iopub.status.idle":"2025-04-22T04:57:57.292159Z","shell.execute_reply.started":"2025-04-22T04:57:57.287768Z","shell.execute_reply":"2025-04-22T04:57:57.291373Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"model = PeftModel.from_pretrained(\n    base_model,\n    adapter_dir,\n    config=config,\n    is_trainable=False,\n    local_files_only=True\n)\nmodel.to(\"cpu\")\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:57:59.728266Z","iopub.execute_input":"2025-04-22T04:57:59.728572Z","iopub.status.idle":"2025-04-22T04:57:59.978229Z","shell.execute_reply.started":"2025-04-22T04:57:59.728522Z","shell.execute_reply":"2025-04-22T04:57:59.977553Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"PeftModelForSeq2SeqLM(\n  (base_model): LoraModel(\n    (model): T5ForConditionalGeneration(\n      (shared): Embedding(32128, 512)\n      (encoder): T5Stack(\n        (embed_tokens): Embedding(32128, 512)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                  (relative_attention_bias): Embedding(32, 8)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-5): 5 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (decoder): T5Stack(\n        (embed_tokens): Embedding(32128, 512)\n        (block): ModuleList(\n          (0): T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                  (relative_attention_bias): Embedding(32, 8)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n          (1-5): 5 x T5Block(\n            (layer): ModuleList(\n              (0): T5LayerSelfAttention(\n                (SelfAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (1): T5LayerCrossAttention(\n                (EncDecAttention): T5Attention(\n                  (q): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (k): Linear(in_features=512, out_features=512, bias=False)\n                  (v): lora.Linear(\n                    (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.05, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=512, out_features=8, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=8, out_features=512, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (o): Linear(in_features=512, out_features=512, bias=False)\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n              (2): T5LayerFF(\n                (DenseReluDense): T5DenseActDense(\n                  (wi): Linear(in_features=512, out_features=2048, bias=False)\n                  (wo): Linear(in_features=2048, out_features=512, bias=False)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                  (act): ReLU()\n                )\n                (layer_norm): T5LayerNorm()\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n        (final_layer_norm): T5LayerNorm()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"texts = [\"Classify text as legal or non-legal: \" + t for t in df_test[\"Text\"]]\nenc = tokenizer(\n    texts,\n    truncation=True,\n    padding=\"max_length\",\n    max_length=512,\n    return_tensors=\"pt\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:04.729032Z","iopub.execute_input":"2025-04-22T04:58:04.729515Z","iopub.status.idle":"2025-04-22T04:58:04.856467Z","shell.execute_reply.started":"2025-04-22T04:58:04.729491Z","shell.execute_reply":"2025-04-22T04:58:04.855908Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"if hasattr(model, \"base_model\"):\n    lm = model.base_model       \nelse:\n    lm = model.get_base_model()  \n\nlm.to(model.device).eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:06.775029Z","iopub.execute_input":"2025-04-22T04:58:06.775653Z","iopub.status.idle":"2025-04-22T04:58:06.791325Z","shell.execute_reply.started":"2025-04-22T04:58:06.775630Z","shell.execute_reply":"2025-04-22T04:58:06.790737Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"LoraModel(\n  (model): T5ForConditionalGeneration(\n    (shared): Embedding(32128, 512)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 512)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o): Linear(in_features=512, out_features=512, bias=False)\n                (relative_attention_bias): Embedding(32, 8)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-5): 5 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (decoder): T5Stack(\n      (embed_tokens): Embedding(32128, 512)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o): Linear(in_features=512, out_features=512, bias=False)\n                (relative_attention_bias): Embedding(32, 8)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-5): 5 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerCrossAttention(\n              (EncDecAttention): T5Attention(\n                (q): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (k): Linear(in_features=512, out_features=512, bias=False)\n                (v): lora.Linear(\n                  (base_layer): Linear(in_features=512, out_features=512, bias=False)\n                  (lora_dropout): ModuleDict(\n                    (default): Dropout(p=0.05, inplace=False)\n                  )\n                  (lora_A): ModuleDict(\n                    (default): Linear(in_features=512, out_features=8, bias=False)\n                  )\n                  (lora_B): ModuleDict(\n                    (default): Linear(in_features=8, out_features=512, bias=False)\n                  )\n                  (lora_embedding_A): ParameterDict()\n                  (lora_embedding_B): ParameterDict()\n                  (lora_magnitude_vector): ModuleDict()\n                )\n                (o): Linear(in_features=512, out_features=512, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (2): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=512, out_features=2048, bias=False)\n                (wo): Linear(in_features=2048, out_features=512, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n  )\n)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlm.to(device)\nenc = enc.to(device)\nwith torch.no_grad():\n    outs = lm.generate(\n        input_ids=enc[\"input_ids\"],\n        attention_mask=enc[\"attention_mask\"],\n        max_new_tokens=2,   \n        num_beams=1,        \n        do_sample=False,\n        use_cache=True\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:09.854849Z","iopub.execute_input":"2025-04-22T04:58:09.855096Z","iopub.status.idle":"2025-04-22T04:58:11.911884Z","shell.execute_reply.started":"2025-04-22T04:58:09.855080Z","shell.execute_reply":"2025-04-22T04:58:11.911110Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:11.913067Z","iopub.execute_input":"2025-04-22T04:58:11.913608Z","iopub.status.idle":"2025-04-22T04:58:11.918046Z","shell.execute_reply.started":"2025-04-22T04:58:11.913584Z","shell.execute_reply":"2025-04-22T04:58:11.917365Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"batch_size = 32\npreds = []\nfor i in range(0, len(texts), batch_size):\n    chunk = tokenizer(\n        texts[i:i+batch_size],\n        padding=True, truncation=True, max_length=512, return_tensors=\"pt\"\n    ).to(device)\n    with torch.no_grad():\n        out = lm.generate(**chunk, max_new_tokens=2, num_beams=1)\n    preds += tokenizer.batch_decode(out, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:14.355427Z","iopub.execute_input":"2025-04-22T04:58:14.355983Z","iopub.status.idle":"2025-04-22T04:58:16.598129Z","shell.execute_reply.started":"2025-04-22T04:58:14.355959Z","shell.execute_reply":"2025-04-22T04:58:16.597388Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"with torch.no_grad():\n    outs = lm.generate(\n        input_ids=enc[\"input_ids\"].to(lm.device),\n        attention_mask=enc[\"attention_mask\"].to(lm.device),\n        max_length=4\n    )\npreds = tokenizer.batch_decode(outs, skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:22.406564Z","iopub.execute_input":"2025-04-22T04:58:22.406813Z","iopub.status.idle":"2025-04-22T04:58:24.343382Z","shell.execute_reply.started":"2025-04-22T04:58:22.406796Z","shell.execute_reply":"2025-04-22T04:58:24.342831Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"true = [\"legal\" if lab == 1 else \"non-legal\" for lab in df_test[\"label\"]]\nprint(\"Classification Report:\\n\",\n      classification_report(true, preds, target_names=[\"legal\",\"non-legal\"]))\n\ncm = confusion_matrix(true, preds, labels=[\"legal\",\"non-legal\"])\ndf_cm = pd.DataFrame(cm,\n                     index=[\"true_legal\",\"true_non-legal\"],\n                     columns=[\"pred_legal\",\"pred_non-legal\"])\ntools.display_dataframe_to_user(\"Confusion Matrix\", df_cm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T04:58:27.695079Z","iopub.execute_input":"2025-04-22T04:58:27.695350Z","iopub.status.idle":"2025-04-22T04:58:27.719647Z","shell.execute_reply.started":"2025-04-22T04:58:27.695330Z","shell.execute_reply":"2025-04-22T04:58:27.718980Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n       legal       0.98      1.00      0.99       322\n   non-legal       0.00      0.00      0.00         5\n\n    accuracy                           0.98       327\n   macro avg       0.49      0.50      0.50       327\nweighted avg       0.97      0.98      0.98       327\n\nConfusion Matrix\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table id=\"itables_fcaf3adc_4191_45fc_a0e7_46beb4a1b76a\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n<thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_legal</th>\n      <th>pred_non-legal</th>\n    </tr>\n  </thead><tbody><tr>\n<td style=\"vertical-align:middle; text-align:left\">\n<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\nwidth=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n    <g style=\"fill:#d9d7fc\">\n        <path d=\"M100,400H500V357H100Z\" />\n        <path d=\"M100,300H400V257H100Z\" />\n        <path d=\"M0,200H400V157H0Z\" />\n        <path d=\"M100,100H500V57H100Z\" />\n        <path d=\"M100,350H500V307H100Z\" />\n        <path d=\"M100,250H400V207H100Z\" />\n        <path d=\"M0,150H400V107H0Z\" />\n        <path d=\"M100,50H500V7H100Z\" />\n    </g>\n    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;400;0\"\n      dur=\"5s\"\n      repeatCount=\"indefinite\" />\n      <animate\n      attributeName=\"x\"\n      values=\"100;100;500\"\n      dur=\"5s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;400;0\"\n      dur=\"3.5s\"\n      repeatCount=\"indefinite\" />\n    <animate\n      attributeName=\"x\"\n      values=\"0;0;400\"\n      dur=\"3.5s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;300;0\"\n      dur=\"3s\"\n      repeatCount=\"indefinite\" />\n    <animate\n      attributeName=\"x\"\n      values=\"100;100;400\"\n      dur=\"3s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n    <animate\n      attributeName=\"width\"\n      values=\"0;400;0\"\n      dur=\"4s\"\n      repeatCount=\"indefinite\" />\n      <animate\n      attributeName=\"x\"\n      values=\"100;100;500\"\n      dur=\"4s\"\n      repeatCount=\"indefinite\" />\n  </rect>\n        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n            <g transform=\"translate(45 50) rotate(-45)\">\n                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n            </g>\n\n            <g transform=\"translate(450 152)\">\n                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n            </g>\n\n            <g transform=\"translate(50 352)\">\n                <polygon points=\"-35,-5 0,-40 35,-5\" />\n                <polygon points=\"-35,10 0,45 35,10\" />\n            </g>\n\n            <g transform=\"translate(75 250)\">\n                <polyline points=\"-30,30 -60,0 -30,-30\" />\n                <polyline points=\"0,30 -30,0 0,-30\" />\n            </g>\n\n            <g transform=\"translate(425 250) rotate(180)\">\n                <polyline points=\"-30,30 -60,0 -30,-30\" />\n                <polyline points=\"0,30 -30,0 0,-30\" />\n            </g>\n        </g>\n    </g>\n</svg>\n</a>\nLoading ITables v2.3.0 from the internet...\n(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n</tr></tbody>\n</table>\n<link href=\"https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.css\" rel=\"stylesheet\">\n<script type=\"module\">\n    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.2.0/dt_bundle.js';\n\n    document.querySelectorAll(\"#itables_fcaf3adc_4191_45fc_a0e7_46beb4a1b76a:not(.dataTable)\").forEach(table => {\n        if (!(table instanceof HTMLTableElement))\n            return;\n\n        // Define the table data\n        const data = [[\"true_legal\", 322, 0], [\"true_non-legal\", 5, 0]];\n\n        // Define the dt_args\n        let dt_args = {\"layout\": {\"topStart\": null, \"topEnd\": null, \"bottomStart\": null, \"bottomEnd\": null}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true};\n        dt_args[\"data\"] = data;\n\n        \n        new DataTable(table, dt_args);\n    });\n</script>\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsteps = [\n    1, 50, 100, 150, 200, 250, 300, 350, 400, 450, 500,\n    550, 600, 650, 700, 750, 800, 850, 900, 950, 1000,\n    1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450,\n    1500, 1550, 1600, 1650, 1700, 1750, 1800, 1850, 1900, 1950,\n    2000, 2050, 2100, 2150, 2200, 2250, 2300, 2350, 2400, 2450,\n    2500, 2550, 2600, 2650, 2700, 2750, 2800, 2850, 2900, 2950,\n    3000, 3050, 3100, 3150, 3200, 3250\n]\nlosses = [\n    17.6094, 16.9826, 14.5749, 10.9941, 7.3075, 4.3825, 2.6361, 1.3448, 0.7896, 0.5283, 0.4013,\n    0.2646, 0.2815, 0.2060, 0.2111, 0.1411, 0.1085, 0.1322, 0.0943, 0.1211, 0.1237,\n    0.0983, 0.0782, 0.0472, 0.0985, 0.0886, 0.0442, 0.0805, 0.0531, 0.0592,\n    0.0890, 0.0606, 0.0365, 0.0570, 0.0813, 0.0572, 0.0240, 0.0677, 0.0493, 0.0466,\n    0.0357, 0.0438, 0.0471, 0.0549, 0.0537, 0.0612, 0.0491, 0.0554, 0.0197, 0.0443,\n    0.0482, 0.0225, 0.0580, 0.0615, 0.0319, 0.0631, 0.0521, 0.0590, 0.0393, 0.0281,\n    0.0243, 0.0284, 0.0528, 0.0410, 0.0408, 0.0393\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T05:20:50.775591Z","iopub.execute_input":"2025-04-22T05:20:50.776153Z","iopub.status.idle":"2025-04-22T05:20:50.782603Z","shell.execute_reply.started":"2025-04-22T05:20:50.776128Z","shell.execute_reply":"2025-04-22T05:20:50.781766Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(steps, losses, marker='o')\nplt.title(\"Тренировочный loss модели LoRA T5-small по эпохам\")\nplt.xlabel(\"Шаг обучения\")\nplt.ylabel(\"Training Loss\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T05:20:53.938795Z","iopub.execute_input":"2025-04-22T05:20:53.939059Z","iopub.status.idle":"2025-04-22T05:20:54.199505Z","shell.execute_reply.started":"2025-04-22T05:20:53.939039Z","shell.execute_reply":"2025-04-22T05:20:54.198809Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":37}]}